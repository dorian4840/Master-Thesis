{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from preprocess_outputs import preprocess_crt_avpu\n",
    "from datasets import create_dataloaders\n",
    "\n",
    "CLINICAL_DATA_PATH = './../DATA/Clean Data/IMPALA_Clinical_Data_202308211019_Raw.csv'\n",
    "CLINICAL_DTYPES_PATH = './../DATA/IMPALAclinicalstudy_Dictionary_2023-09-25.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_clinical_df(path):\n",
    "    \"\"\" Load clinical data into a Pandas DataFrame. \"\"\"\n",
    "    return pd.read_csv(path, low_memory=False)\n",
    "\n",
    "\n",
    "def read_clinical_dtype_dict(path):\n",
    "    \"\"\" Load clinical dict containing all variable names and their properties. \"\"\"\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df['Variable'].str.startswith(tuple(['recru', 'dly', 'record_id']))]\n",
    "\n",
    "    dtype_dict = defaultdict(list)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        dtype_dict[row['Field Type']].append(row['Variable'])\n",
    "    \n",
    "    # {k: v.append('dly_time') for k, v in dtype_dict.items()}\n",
    "    del df\n",
    "\n",
    "    return dtype_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clinical_df = read_clinical_df(CLINICAL_DATA_PATH)\n",
    "dtype_dict = read_clinical_dtype_dict(CLINICAL_DTYPES_PATH)\n",
    "\n",
    "# Checkbox column names in dtype_df do not correspond 1-on-1 with clinical data\n",
    "checkbox_dict = {\n",
    "    'recru_hdu_admission_reason' : ['recru_resp', 'recru_circu', 'recru_neuro',\n",
    "                                    'recru_nurse', 'recru_unclear', 'recru_hdu_other'],\n",
    "    'recru_medication_specfy' : clinical_df.columns[clinical_df.columns.str.startswith('recru_medication_specfy___')].to_list(),\n",
    "    'dly_new_drug' : clinical_df.columns[clinical_df.columns.str.startswith('dly_new_drug___')].to_list(),\n",
    "}\n",
    "\n",
    "dtype_dict['checkbox'] = [l for s in checkbox_dict.values() for l in s]\n",
    "# dtype_dict['checkbox'].append('dly_time')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data per datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def intersection(l1, l2):\n",
    "    \"\"\" Create intersection of two lists. \"\"\"\n",
    "    return [v1 for v1 in l1 if v1 in l2]\n",
    "\n",
    "\n",
    "def split_per_dtype(c_df, d_dict):\n",
    "    \"\"\"\n",
    "    Split the clinical dataset per datatype.\n",
    "    \"\"\"\n",
    "\n",
    "    c_df = c_df.copy()  # Might remove later\n",
    "    d_dict = d_dict.copy() # Might remove later\n",
    "\n",
    "    # Remove rows that have no daily time (as those are duplicates of the row above)\n",
    "    c_df = c_df[-pd.isna(c_df['dly_time'])]\n",
    "    c_df.reset_index(inplace=True)\n",
    "\n",
    "    # Replace missing values with -1\n",
    "    c_df.replace(to_replace=99, value=-1, inplace=True)\n",
    "    c_df.fillna(-1, inplace=True)\n",
    "\n",
    "    # Only select columns that appear in clinical data\n",
    "    dtype_columns = {k : intersection(v, c_df.columns.to_list()) for k, v in d_dict.items()}\n",
    "    dtype_df = {k : c_df[v] for k, v in dtype_columns.items()}\n",
    "\n",
    "    return dtype_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtype_df = split_per_dtype(clinical_df, dtype_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns if too many values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_columns(dtype_df, threshold):\n",
    "    \"\"\" Remove columns if the ratio of missing values exceeds the threshold. \"\"\"\n",
    "\n",
    "    for type_, df in dtype_df.items():\n",
    "        drop = []\n",
    "\n",
    "        for col in df:\n",
    "            if -1 in df[col].value_counts(normalize=True).to_dict().keys() and \\\n",
    "                    df[col].value_counts(normalize=True).to_dict()[-1] > threshold:\n",
    "\n",
    "                drop.append(col)\n",
    "        \n",
    "        print(f'{type_}: removed {len(drop)} columns')\n",
    "        dtype_df[type_] = dtype_df[type_].drop(drop, axis=1)\n",
    "    \n",
    "    return dtype_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtype_df = remove_columns(dtype_df, 0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess text and categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_text_data(dtype_df):\n",
    "    \"\"\"\n",
    "    Split the text data into numerical, record_id, dates and text\n",
    "    \"\"\"\n",
    "\n",
    "    dtype_df = dtype_df.copy()\n",
    "\n",
    "    # Split numerical columns\n",
    "    num_df = dtype_df['text'].select_dtypes(include=['float64', 'int64'])\n",
    "    valid_num_columns = num_df.columns.to_list()\n",
    "    dtype_df['text'] = dtype_df['text'].drop(valid_num_columns, axis=1)\n",
    "    dtype_df['numerical'] = num_df\n",
    "\n",
    "    # Split record_id\n",
    "    if 'record_id' in dtype_df['text'].columns:\n",
    "        record_id = dtype_df['text']['record_id']\n",
    "        dtype_df['text'] = dtype_df['text'].drop('record_id', axis=1)\n",
    "        dtype_df['record_id'] = record_id\n",
    "\n",
    "    # Split date columns (columns handpicked)\n",
    "    date_df = dtype_df['text'].filter(\n",
    "        [\"recru_interview_date_\", \"recru_hospital_admission_date\",\n",
    "         \"recru_hdu_admission_date\", \"recru_dob\", \"recru_bloodculture_time\",\n",
    "         \"recru_lactate_sample_time\", \"recru_storage_spec_time\",\n",
    "         \"recru_nasal_swab_time\", \"recru_urine_time\", \"dly_time\",\n",
    "         \"dly_time_new_cie1a\", \"dly_time_new_cie2\", \"dly_time_new_cie3\",\n",
    "         \"dly_time_new_cie4\", \"dly_time_new_cie5\", \"dly_time_new_cie6\"])\n",
    "    \n",
    "    dtype_df['dates'] = date_df\n",
    "    dtype_df['text'] = dtype_df['text'].drop(date_df.columns, axis=1)\n",
    "\n",
    "    return dtype_df\n",
    "\n",
    "\n",
    "def one_hot_encoding(df):\n",
    "    \"\"\"\n",
    "    Convert categorical columns to multiple binary columns and add them to the\n",
    "    end of the DataFrame. Remove binary columns that are created for\n",
    "    missing/NaN values.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    categorical_columns = df.columns.to_list()\n",
    "    drop = []\n",
    "\n",
    "    for col in categorical_columns:\n",
    "\n",
    "        if -1 in df[col].value_counts().to_dict().keys():\n",
    "            DROP_FIRST = True\n",
    "\n",
    "        else:\n",
    "            DROP_FIRST = False\n",
    "\n",
    "        df = df.join(pd.get_dummies(df[col],\n",
    "                                    dummy_na=False, \n",
    "                                    prefix=col,\n",
    "                                    sparse=True,\n",
    "                                    drop_first=DROP_FIRST,\n",
    "                                    dtype=float))\n",
    "\n",
    "        # Drop original categorical column\n",
    "        drop.append(col)\n",
    "\n",
    "    df = df.drop(drop, axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtype_df['radio'] = one_hot_encoding(dtype_df['radio'])\n",
    "\n",
    "dtype_df = split_text_data(dtype_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_dtypes = ['radio', 'yesno', 'checkbox', 'calc', 'numerical']\n",
    "string_dtypes = ['text', 'record_id', 'dates']\n",
    "\n",
    "numerical_data = np.concatenate(([v for k, v in dtype_df.items() \\\n",
    "                                  if k in numerical_dtypes]), axis=1)\n",
    "\n",
    "# Normalize the data\n",
    "data = normalize(numerical_data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_PCA(data, visualize=True):\n",
    "    \"\"\"\n",
    "    Normalize the data and perform PCA to reduce dimensionality.\n",
    "    If visualize is True, plot the explained variance per PC.\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform Principal Component Analysis\n",
    "    pca = PCA(n_components='mle')\n",
    "    pca.fit(data)\n",
    "    new_data = pca.transform(data)\n",
    "\n",
    "    if visualize:\n",
    "        plt.plot(range(pca.n_components_), pca.explained_variance_ratio_)\n",
    "        plt.title('Explained variance ratio per principal component')\n",
    "        plt.xlabel('Number of components')\n",
    "        plt.ylabel('Ratio of explained variance')\n",
    "        plt.legend(['Explained Variance', \"Number of PCs found using Minka's MLE\"])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data = perform_PCA(data, visualize=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = preprocess_crt_avpu(CLINICAL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sliding_window_backward(data, outputs, datetimes, admission_dates, record_ids, sample_window_hours):\n",
    "    \"\"\"\n",
    "    Apply a sliding window over the given data.\n",
    "    :param data:     NumPy Array containing the clinical data.\n",
    "    :param outputs:  Pandas Dataframe containing CRT and AVPU values per time.\n",
    "    :param datetimes: Pandas DataFrame containing the time at each data point.\n",
    "    :param record_ids: Pandas DataFrame containing the record IDs per patient.\n",
    "    \"\"\"\n",
    "    \n",
    "    X, y = [], []\n",
    "\n",
    "    for record_id, df in record_ids.groupby(by='record_id', observed=True):\n",
    "\n",
    "        idx = df.index\n",
    "        del df\n",
    "\n",
    "        curr_data = data[idx, :]\n",
    "        curr_output = outputs[record_id]\n",
    "        curr_datetime = datetimes.iloc[idx]\n",
    "\n",
    "        curr_data = np.concatenate((curr_data[0:1, :], curr_data))\n",
    "        curr_datetime = pd.concat([pd.Series(admission_dates[record_id]), curr_datetime],\n",
    "                                  ignore_index=True)\n",
    "        curr_datetime = pd.to_datetime(curr_datetime, format='mixed')\n",
    "\n",
    "        for end in curr_datetime[::-1]:\n",
    "\n",
    "            start = end - pd.Timedelta(sample_window_hours, unit='h')\n",
    "            idx = curr_datetime.between(start, end)\n",
    "            window = curr_data[idx]\n",
    "\n",
    "            if window.shape[0] < (sample_window_hours / 4) + 1:\n",
    "                continue\n",
    "\n",
    "            elif window.shape[0] > (sample_window_hours / 4) + 1: # Remove first entry\n",
    "                window = window[-int((sample_window_hours / 4) + 1):]\n",
    "            \n",
    "            # Calculate to which output the end of the window lies closest\n",
    "            nearest_output_idx = np.argmin( [abs(end - t) for t in curr_output.index] )\n",
    "\n",
    "            X.append(window.T)\n",
    "            y.append(curr_output.iloc[nearest_output_idx].values)\n",
    "\n",
    "    X = np.array(X) # Shape: samples, dimensions, time\n",
    "    y = np.array(y) # Shape: samples, dimensions\n",
    "\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datetimes = dtype_df['dates']['dly_time']\n",
    "admission_dates = {k : v['recru_hospital_admission_date'].iloc[0] for \\\n",
    "                   k, v in clinical_df.groupby('record_id')}\n",
    "\n",
    "X, y = sliding_window_backward(data, outputs, datetimes, admission_dates,\n",
    "                      dtype_df['record_id'].to_frame(), 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sliding_window_forward(data, outputs, datetimes, admission_dates, record_ids, sample_window_hours):\n",
    "    \"\"\"\n",
    "    Apply a sliding window over the given data.\n",
    "    :param data:     NumPy Array containing the clinical data.\n",
    "    :param outputs:  Pandas Dataframe containing CRT and AVPU values per time.\n",
    "    :param datetimes: Pandas DataFrame containing the time at each data point.\n",
    "    :param record_ids: Pandas DataFrame containing the record IDs per patient.\n",
    "    \"\"\"\n",
    "    \n",
    "    X, y = [], []\n",
    "\n",
    "    for record_id, df in record_ids.groupby(by='record_id', observed=True):\n",
    "\n",
    "        idx = df.index\n",
    "        del df\n",
    "        curr_data = data[idx, :]\n",
    "        curr_output = outputs[record_id]\n",
    "        curr_datetime = datetimes.iloc[idx]\n",
    "\n",
    "        curr_data = np.concatenate((curr_data[0:1, :], curr_data))\n",
    "        curr_datetime = pd.concat([pd.Series(admission_dates[record_id]), curr_datetime],\n",
    "                                  ignore_index=True)\n",
    "        curr_datetime = pd.to_datetime(curr_datetime, format='mixed')\n",
    "\n",
    "        for start in curr_datetime:\n",
    "\n",
    "            end = start + pd.Timedelta(sample_window_hours, unit='h')\n",
    "            idx = curr_datetime.between(start, end)\n",
    "            window = curr_data[idx]\n",
    "\n",
    "            # Only continue if window is the appropriate size (5016 windows)\n",
    "            if window.shape[0] == (sample_window_hours / 4) + 1:\n",
    "\n",
    "                # Calculate to which output the end of the window lies closest\n",
    "                nearest_output_idx = np.argmin( [abs(end - t) for t in curr_output.index] )\n",
    "\n",
    "                X.append(window.T)\n",
    "                y.append(curr_output.iloc[nearest_output_idx].values)\n",
    "\n",
    "\n",
    "    X = np.array(X) # Shape: samples, dimensions, time\n",
    "    y = np.array(y) # Shape: samples, dimensions\n",
    "\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datetimes = dtype_df['dates']['dly_time']\n",
    "admission_dates = {k : v['recru_hospital_admission_date'].iloc[0] for \\\n",
    "                   k, v in clinical_df.groupby('record_id')}\n",
    "\n",
    "X, y = sliding_window_forward(data, outputs, datetimes, admission_dates,\n",
    "                      dtype_df['record_id'].to_frame(), 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn data to PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = create_dataloaders(X, y,\n",
    "                                                                       batch_size=32,\n",
    "                                                                       seed=42)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
